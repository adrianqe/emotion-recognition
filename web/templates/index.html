<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconocimiento de Emociones - IA</title>

    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #fff;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 30px;
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .subtitle {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .model-info {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }

        .main-content {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 20px;
        }

        @media (max-width: 968px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }

        .video-section {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        #video {
            width: 100%;
            height: auto;
            border-radius: 10px;
            background: #000;
            display: block;
        }

        canvas {
            display: none;
        }

        .controls {
            margin-top: 15px;
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
        }

        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 1em;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .sidebar {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        .card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .emotion-display {
            text-align: center;
        }

        .emotion-emoji {
            font-size: 5em;
            margin: 20px 0;
            animation: pulse 2s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .emotion-name {
            font-size: 2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .confidence {
            font-size: 1.5em;
            opacity: 0.9;
        }

        .probabilities h3 {
            margin-bottom: 15px;
        }

        .prob-bar {
            margin-bottom: 15px;
        }

        .prob-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-size: 0.9em;
        }

        .bar-container {
            height: 20px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            overflow: hidden;
        }

        .bar-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.3s ease;
            border-radius: 10px;
        }

        .stats {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
            text-align: center;
        }

        .stat-item h4 {
            font-size: 0.9em;
            opacity: 0.8;
            margin-bottom: 5px;
        }

        .stat-item p {
            font-size: 1.5em;
            font-weight: bold;
        }

        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 10px;
            text-align: center;
        }

        .status.success { background: rgba(76, 175, 80, 0.3); }
        .status.error { background: rgba(244, 67, 54, 0.3); }
        .status.info { background: rgba(33, 150, 243, 0.3); }

        footer {
            text-align: center;
            margin-top: 30px;
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üé≠ Reconocimiento de Emociones</h1>
            <p class="subtitle">Sistema de IA en Tiempo Real con tu Webcam</p>
        </header>

        <div class="model-info">
            <strong>Modelo:</strong> {{ model_info.name }} | 
            <strong>Precisi√≥n:</strong> {{ model_info.accuracy }}
        </div>

        <div class="main-content">
            <div class="video-section">
                <video id="video" autoplay playsinline></video>
                <canvas id="canvas"></canvas>
                
                <div id="statusMessage" class="status info" style="display: none;"></div>
                
                <div class="controls">
                    <button id="startBtn">‚ñ∂Ô∏è Iniciar C√°mara</button>
                    <button id="detectBtn" disabled>üîç Detectar Emoci√≥n</button>
                    <button id="autoBtn" disabled>üîÑ Modo Autom√°tico</button>
                </div>
            </div>

            <div class="sidebar">
                <div class="card emotion-display">
                    <h3>Emoci√≥n Detectada</h3>
                    <div class="emotion-emoji" id="emotionEmoji">üòê</div>
                    <div class="emotion-name" id="emotionName">Neutral</div>
                    <div class="confidence" id="confidence">0%</div>
                </div>

                <div class="card probabilities">
                    <h3>Probabilidades</h3>
                    <div id="probBars"></div>
                </div>

                <div class="card stats">
                    <div class="stat-item">
                        <h4>Detecciones</h4>
                        <p id="detectionCount">0</p>
                    </div>
                    <div class="stat-item">
                        <h4>Rostros</h4>
                        <p id="faceCount">0</p>
                    </div>
                </div>
            </div>
        </div>

        <footer>
            <p>Proyecto de Inteligencia Artificial | Python + TensorFlow + Keras + Flask</p>
        </footer>
    </div>

<script>
    const EMOTIONS = ['Enojado', 'Disgusto', 'Miedo', 'Feliz', 'Neutral', 'Triste', 'Sorpresa'];
    const EMOJIS = ['üò†', 'ü§¢', 'üò®', 'üòä', 'üòê', 'üò¢', 'üòÆ'];
    
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvas');
    let ctx = canvas.getContext('2d');
    let stream = null;
    let isAutoMode = false;
    let detectionCount = 0;
    let modelsLoaded = false;

    // Cargar modelos de face-api.js
    async function loadFaceDetectionModels() {
        try {
            showStatus('üì¶ Cargando modelos de detecci√≥n facial...', 'info');
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
            modelsLoaded = true;
            showStatus('‚úÖ Modelos de detecci√≥n cargados', 'success');
        } catch (error) {
            console.error('Error loading face-api models:', error);
            showStatus('‚ö†Ô∏è Usando detecci√≥n del servidor', 'info');
        }
    }

    // Crear barras de probabilidad
    function createProbabilityBars() {
        const container = document.getElementById('probBars');
        container.innerHTML = EMOTIONS.map((emotion, idx) => `
            <div class="prob-bar">
                <div class="prob-label">
                    <span>${EMOJIS[idx]} ${emotion}</span>
                    <span id="percent-${idx}">0%</span>
                </div>
                <div class="bar-container">
                    <div class="bar-fill" id="bar-${idx}" style="width: 0%"></div>
                </div>
            </div>
        `).join('');
    }

    // Mostrar mensaje de estado
    function showStatus(message, type = 'info') {
        const statusEl = document.getElementById('statusMessage');
        statusEl.textContent = message;
        statusEl.className = `status ${type}`;
        statusEl.style.display = 'block';
        
        if (type !== 'error') {
            setTimeout(() => {
                statusEl.style.display = 'none';
            }, 3000);
        }
    }

    // Iniciar c√°mara
    async function startCamera() {
        try {
            stream = await navigator.mediaDevices.getUserMedia({ 
                video: { 
                    facingMode: 'user',
                    width: { ideal: 640 },
                    height: { ideal: 480 }
                } 
            });
            video.srcObject = stream;
            
            video.onloadedmetadata = () => {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                document.getElementById('detectBtn').disabled = false;
                document.getElementById('autoBtn').disabled = false;
                document.getElementById('startBtn').textContent = '‚è∏Ô∏è Detener C√°mara';
                showStatus('‚úÖ C√°mara iniciada correctamente', 'success');
            };
        } catch (error) {
            showStatus('‚ùå No se pudo acceder a la c√°mara: ' + error.message, 'error');
        }
    }

    // Detener c√°mara
    function stopCamera() {
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
            video.srcObject = null;
            isAutoMode = false;
            document.getElementById('detectBtn').disabled = true;
            document.getElementById('autoBtn').disabled = true;
            document.getElementById('startBtn').textContent = '‚ñ∂Ô∏è Iniciar C√°mara';
            showStatus('C√°mara detenida', 'info');
        }
    }

    // Detectar rostro con face-api.js (en el navegador)
    async function detectFaceInBrowser() {
        if (!modelsLoaded) return null;
        
        try {
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({
                inputSize: 224,
                scoreThreshold: 0.5
            }));
            
            return detections.length > 0 ? detections[0].box : null;
        } catch (error) {
            console.error('Face detection error:', error);
            return null;
        }
    }

    // Recortar rostro de la imagen
    function cropFace(imageData, faceBox) {
        if (!faceBox) return imageData;
        
        const tempCanvas = document.createElement('canvas');
        const tempCtx = tempCanvas.getContext('2d');
        
        // Expandir un poco el box para incluir m√°s contexto
        const padding = 20;
        const x = Math.max(0, faceBox.x - padding);
        const y = Math.max(0, faceBox.y - padding);
        const width = Math.min(canvas.width - x, faceBox.width + padding * 2);
        const height = Math.min(canvas.height - y, faceBox.height + padding * 2);
        
        tempCanvas.width = width;
        tempCanvas.height = height;
        
        // Dibujar solo la regi√≥n del rostro
        tempCtx.drawImage(canvas, x, y, width, height, 0, 0, width, height);
        
        return tempCanvas.toDataURL('image/jpeg', 0.8);
    }

    // Detectar emoci√≥n
    async function detectEmotion() {
        try {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            showStatus('üîç Detectando rostro...', 'info');
            
            // Intentar detectar rostro en el navegador primero
            let faceBox = null;
            if (modelsLoaded) {
                faceBox = await detectFaceInBrowser();
                
                if (!faceBox) {
                    showStatus('‚ö†Ô∏è No se detect√≥ rostro. Aseg√∫rate de estar frente a la c√°mara.', 'error');
                    return;
                }
                
                // Dibujar rect√°ngulo del rostro detectado
                ctx.strokeStyle = '#00ff00';
                ctx.lineWidth = 3;
                ctx.strokeRect(faceBox.x, faceBox.y, faceBox.width, faceBox.height);
            }
            
            // Obtener imagen (recortada si hay rostro detectado)
            const imageData = faceBox ? cropFace(null, faceBox) : canvas.toDataURL('image/jpeg', 0.8);
            
            showStatus('üß† Analizando emoci√≥n...', 'info');
            
            const response = await fetch('/predict', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: imageData })
            });
            
            const data = await response.json();
            
            if (data.success) {
                detectionCount++;
                document.getElementById('detectionCount').textContent = detectionCount;
                document.getElementById('faceCount').textContent = data.faces_detected || 1;
                
                if (data.results && data.results.length > 0) {
                    const result = data.results[0];
                    
                    document.getElementById('emotionEmoji').textContent = result.emoji;
                    document.getElementById('emotionName').textContent = result.emotion;
                    document.getElementById('confidence').textContent = 
                        `${result.confidence.toFixed(1)}% confianza`;
                    
                    // Actualizar barras
                    Object.entries(result.probabilities).forEach(([emotion, prob]) => {
                        const idx = EMOTIONS.indexOf(emotion);
                        if (idx !== -1) {
                            const bar = document.getElementById(`bar-${idx}`);
                            const percent = document.getElementById(`percent-${idx}`);
                            if (bar && percent) {
                                bar.style.width = `${prob}%`;
                                percent.textContent = `${prob.toFixed(1)}%`;
                            }
                        }
                    });
                    
                    showStatus(`‚úÖ ${result.emoji} ${result.emotion} detectado`, 'success');
                } else {
                    showStatus('‚ö†Ô∏è No se pudo clasificar la emoci√≥n', 'error');
                }
            } else {
                showStatus('‚ùå Error: ' + (data.error || 'Error desconocido'), 'error');
            }
            
        } catch (error) {
            console.error('Detection error:', error);
            showStatus('‚ùå Error en la detecci√≥n: ' + error.message, 'error');
        }
    }

    // Modo autom√°tico
    async function autoDetect() {
        if (isAutoMode) {
            await detectEmotion();
            setTimeout(autoDetect, 3000); // Cada 3 segundos (menos frecuente para mejor rendimiento)
        }
    }

    // Event listeners
    document.getElementById('startBtn').addEventListener('click', () => {
        if (stream) {
            stopCamera();
        } else {
            startCamera();
        }
    });

    document.getElementById('detectBtn').addEventListener('click', detectEmotion);

    document.getElementById('autoBtn').addEventListener('click', () => {
        isAutoMode = !isAutoMode;
        const btn = document.getElementById('autoBtn');
        if (isAutoMode) {
            btn.textContent = '‚è∏Ô∏è Detener Auto';
            autoDetect();
            showStatus('üîÑ Modo autom√°tico activado (cada 3 seg)', 'info');
        } else {
            btn.textContent = 'üîÑ Modo Autom√°tico';
            showStatus('Modo autom√°tico desactivado', 'info');
        }
    });

    // Inicializar
    createProbabilityBars();
    loadFaceDetectionModels();
</script>
</body>
</html>